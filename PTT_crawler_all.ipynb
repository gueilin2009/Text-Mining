{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTT 看板(Board) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Culture, Consumption, Politics, Gossip....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Skills：\n",
    "1.Web Crawler\n",
    "2.DataPipeLine\n",
    "3.Dockefile/Docker/DockerHub(port)\n",
    "4.DataMining(numeric, text mining, image, opinion)\n",
    "5.Machine Learning/Sentiment analysis/Deep learning\n",
    "6.Text categorization: Topic minin, Sentiment anaylysis, Opinion mining\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy MongoDB docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把爬取的資料部署裝到容器中, 也可在Linux中直接執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!curl -fsSL get.docker.com -o get-docker.sh | sh  #改以Linux部署docker容器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker run -p 27017:27017 -v $(pwd)/mongodb_data:/data/db --name some-mongo -d mongo  #利用port號run一台mongodb的容器,把本地端資料餵進去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/25/44b0fc81668a883739b108d9bd0c95b24f0b0204cb2dc93e0f259e173670/pymongo-3.7.2-cp36-cp36m-win_amd64.whl (315kB)\n",
      "Installing collected packages: pymongo\n",
      "Successfully installed pymongo-3.7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo  #載入pymongo連線套件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Pipeline Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\user\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from beautifulsoup4) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "#功能 (url位址即檔案)\n",
    "'''\n",
    "1.將request的網址自動寫入檔案\n",
    "2.任意設定PTT看板(Board)分類與爬取筆數(Num),每個板約3000多個網頁/每頁約10-20筆文章\n",
    "3.自動化擷取各檔案的頁面資訊,餵到雲端容器中\n",
    "4.創BOW(Bag of Words)詞向量,依字頻排序（ex：英文部分）\n",
    ".....\n",
    ".....\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import re\n",
    "!pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter  \n",
    "\n",
    "\n",
    "\n",
    "def get_ptt(Board, Num):  \n",
    "    main_page = 'https://www.ptt.cc/bbs/%s'%Board + '/index.html'  \n",
    "    response = requests.get(main_page)\n",
    "    total_page = int(response.text.split('a class=\"btn wide\" href=\"/bbs/%s'%Board +'/index')[2].split('.html\">&lsaquo; 上頁</a>')[0]) + 1\n",
    "    url_template = 'https://www.ptt.cc/bbs/%s'%Board + '/index%s.html'    \n",
    "    pages_to_crawl = Num  \n",
    "    for page in range(total_page, total_page - pages_to_crawl,-1):  \n",
    "        urls = url_template%page  \n",
    "        return urls\n",
    "    \n",
    "    \n",
    "def get_ptt_detail(urls, Board, Num):   \n",
    "    with open('./ptt_data_all/%s'%Num, 'w') as f:   \n",
    "        html=f.write(requests.get(urls, headers={\"cookie\":\"over18=1\"}).text)\n",
    "    with open('./ptt_data_all/%s'%Num) as f: \n",
    "        html=f.read()\n",
    "        detail_urls_list = re.findall('/bbs/%s'%Board + '/M.{18}html', html)\n",
    "        return detail_urls_list  \n",
    "\n",
    "\n",
    "def parse_ptt_detail(detail_urls_list):\n",
    "    for i in range(len(detail_urls_list)):\n",
    "        with open('./ptt_data_all/details/%s'%i, 'w') as f:   #linux可直接touch files\n",
    "            html = f.write(requests.get('https://www.ptt.cc/'+ detail_urls_list[i]).text)\n",
    "        with open('./ptt_data_all/details/%s'%i) as f:\n",
    "            html = f.read()\n",
    "            soup = BeautifulSoup(html, 'lxml') \n",
    "            metas = [tag.text for tag in soup.find_all('span', {\"class\":\"article-meta-value\"})] \n",
    "            ptt_data = {}\n",
    "            ptt_data['author']  = metas[0]\n",
    "            ptt_data['board'] = metas[1]\n",
    "            ptt_data['title'] = metas[2]\n",
    "            ptt_data['dt'] = metas[3]\n",
    "            content = [tag.text for tag in soup.find_all('div', {\"id\":\"main-content\"}, {\"class\":\"bbs-screen bbs-content\"})] \n",
    "            ptt_data['content'] = content\n",
    "            return ptt_data\n",
    "\n",
    "    \n",
    "#def save_to_mongo(ptt_data):   #塞入容器再壓成image, 或直接寫成docker file(sh)\n",
    "#    client = MongoClient()\n",
    "#    client.crawler.ptt.insert(ptt_data)  #crawler: database, ptt: collection\n",
    "#    client = MongoClient()\n",
    "#    text = client.crawler.ptt.get('content')\n",
    "#    return client, text\n",
    "\n",
    "\n",
    "\n",
    "#def cnt_words(text, res={}):  #進入容器, 取出文章後, 開始創BOW,或用R-progam斷詞套件(合併寫在docker file中)\n",
    "#    bag = text.replace(',','').replace('.','').replace('?','').lower().split()\n",
    "#    for word in bag:\n",
    "#        if word not in stopwords:  #stopwords是另一篇文章\n",
    "#            if word in res:\n",
    "#                res[word] += 1    #統計wordf freq\n",
    "#            else:\n",
    "#                res[word] = 1\n",
    "#    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#假設設定要爬NBA板20頁\n",
    "\n",
    "urls = get_ptt('NBA', 20)\n",
    "detail_urls = get_ptt_detail(urls, 'NBA', 20)\n",
    "ptt_data = parse_ptt_detail(detail_urls)\n",
    "#save_to_mongo(ptt_data)\n",
    "#res = cnt_words(speech, Counter())   \n",
    "#res.most_common()   #word freq排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
